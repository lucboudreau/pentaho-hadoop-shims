<?xml version="1.0" encoding="UTF-8"?>
<!--===========================================================================
HITACHI VANTARA PROPRIETARY AND CONFIDENTIAL

Copyright 2002 - ${copyright.year} Hitachi Vantara. All rights reserved.

NOTICE: All information including source code contained herein is, and
remains the sole property of Hitachi Vantara and its licensors. The intellectual
and technical concepts contained herein are proprietary and confidential
to, and are trade secrets of Hitachi Vantara and may be covered by U.S. and foreign
patents, or patents in process, and are protected by trade secret and
copyright laws. The receipt or possession of this source code and/or related
information does not convey or imply any rights to reproduce, disclose or
distribute its contents, or to manufacture, use, or sell anything that it
may describe, in whole or in part. Any reproduction, modification, distribution,
or public display of this information without the express written authorization
from Hitachi Vantara is strictly prohibited and in violation of applicable laws and
international treaties. Access to the source code contained herein is strictly
prohibited to anyone except those individuals and entities who have executed
confidentiality and non-disclosure agreements or other agreements with Hitachi Vantara,
explicitly covering such access.
============================================================================-->
<!--
  - These settings are the minimum necessary MapReduce settings for the Hortonworks 2.0 Sandbox. The settings for your cluster may be different,
  - please see the descriptions below along with your vendor documentation for the appropriate property values.
  -
  - The Apache defaults (not necessarily vendor-compatible) are listed here:
  - http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
  -->
<configuration>
  <!--
    - The following property specifies application classpath.
    -->
  <property>
    <name>mapreduce.application.classpath</name>
    <value>$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/usr/hdp/${hdp.version}/hadoop/lib/hadoop-lzo-0.6.0.${hdp.version}.jar:/etc/hadoop/conf/secure</value>
  </property>

  <!--
    - The following property specifies mapreduce framework path.
    -->
  <property>
    <name>mapreduce.application.framework.path</name>
    <value>/hdp/apps/${hdp.version}/mapreduce/mapreduce.tar.gz#mr-framework</value>
  </property>

  <!--
    - The following property specifies in which mode to run MapReduce jobs.
    - the choices are local, classic, or yarn:
    -
    - local: run the MapReduce tasks on this client machine
    - classic: run job(s) on the cluster using MapReduce v1
    - yarn: run job(s) on the cluster using MapReduce v2 (on YARN)
    -
    -->
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>

  <!--
    - The following property allows to run MR jobs cross-platformly.
    - It means that jobs created on Windows MR client can be run on Linux cluster or vice versa.
    -
    -->
  <property>
    <name>mapreduce.app-submission.cross-platform</name>
    <value>true</value>
  </property>

  <!--
    - This property specifies the hostname:port value for the MapReduce JobHistory Server of your cluster/sandbox. Update this property accordingly
    -->
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value>sandbox.hortonworks.com:10020</value>
  </property>

</configuration>
